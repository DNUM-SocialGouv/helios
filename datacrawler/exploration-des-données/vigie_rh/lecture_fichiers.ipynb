{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture fichier vigierh_anneemois_contrat et chargement en BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Chemin vers votre fichier Parquet\n",
    "FILE_PATH_PARQUET = '../vigie_rh/fichiers/parquet/vigierh_anneemois_contrat_2024_01_01.parquet'\n",
    "\n",
    "# URL BDD\n",
    "PATH_BDD = 'postgresql://helios:h3li0s@localhost:5532/helios-preprod'\n",
    "\n",
    "# Connexion √† la base\n",
    "engine = create_engine(PATH_BDD)\n",
    "\n",
    "# üì• Lire le fichier Parquet\n",
    "df = pd.read_parquet(FILE_PATH_PARQUET, engine='pyarrow')\n",
    "\n",
    "# Correspondance des colonnes (Parquet -> Table SQL)\n",
    "column_mapping = {\n",
    "    'finess_et': 'numero_finess',\n",
    "    'year': 'annee',\n",
    "    'month': 'mois',\n",
    "    'nature_contrat': 'type_contrat',\n",
    "    'effectif': 'effectif'\n",
    "}\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Supprimer les anciennes donn√©es AVANT insertion\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DELETE FROM vigie_rh_contrat;\"))  # Supprime toutes les donn√©es\n",
    "    conn.commit()\n",
    "\n",
    "# Ins√©rer les nouvelles donn√©es en respectant la structure de la table\n",
    "df.to_sql(\n",
    "    'vigie_rh_contrat', engine, \n",
    "    if_exists='append',  # Ajoute les nouvelles donn√©es sans modifier la structure\n",
    "    index=False,  # Ne pas ins√©rer l'index Pandas\n",
    "    chunksize=1000,  # Insertion par lots pour optimiser la performance\n",
    "    method='multi'  # Regrouper les INSERT pour am√©liorer la vitesse\n",
    ")\n",
    "\n",
    "print(\" Donn√©es ins√©r√©es avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture fichier vigierh_anneemois_profession2 (groupe) et chargement en BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Chemin vers votre fichier Parquet\n",
    "FILE_PATH_PARQUET = '../vigie_rh/fichiers/parquet/vigierh_anneemois_profession2_2024_01_01.parquet'\n",
    "\n",
    "# URL BDD\n",
    "PATH_BDD = 'postgresql://helios:h3li0s@localhost:5532/helios-preprod'\n",
    "\n",
    "# Connexion √† la base\n",
    "engine = create_engine(PATH_BDD)\n",
    "\n",
    "# üì• Lire le fichier Parquet\n",
    "df = pd.read_parquet(FILE_PATH_PARQUET, engine='pyarrow')\n",
    "\n",
    "# Correspondance des colonnes (Parquet -> Table SQL)\n",
    "column_mapping = {\n",
    "    'finess_et': 'numero_finess',\n",
    "    'year': 'annee',\n",
    "    'month': 'mois',\n",
    "    'profession2': 'profession',\n",
    "    'effectif': 'effectif',\n",
    "    'ind_qual_effectif':'indic_qualite_effectif',\n",
    "    'ind_redr_effectif':'indic_redressement_effectif',\n",
    "    'ind_masq_effectif':'indic_masque_secret_effectif',\n",
    "\n",
    "}\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Supprimer les anciennes donn√©es AVANT insertion\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DELETE FROM vigie_rh_profession_groupe;\"))  # Supprime toutes les donn√©es\n",
    "    conn.commit()\n",
    "\n",
    "# Ins√©rer les nouvelles donn√©es en respectant la structure de la table\n",
    "df.to_sql(\n",
    "    'vigie_rh_profession_groupe', engine, \n",
    "    if_exists='append',  # Ajoute les nouvelles donn√©es sans modifier la structure\n",
    "    index=False,  # Ne pas ins√©rer l'index Pandas\n",
    "    chunksize=1000,  # Insertion par lots pour optimiser la performance\n",
    "    method='multi'  # Regrouper les INSERT pour am√©liorer la vitesse\n",
    ")\n",
    "\n",
    "print(\" Donn√©es ins√©r√©es avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture fichier vigierh_anneemois_profession1 (fili√©re) et chargement en BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Chemin vers votre fichier Parquet\n",
    "FILE_PATH_PARQUET = '../vigie_rh/fichiers/parquet/vigierh_anneemois_profession1_2024_01_01.parquet'\n",
    "\n",
    "# URL BDD\n",
    "PATH_BDD = 'postgresql://helios:h3li0s@localhost:5532/helios-preprod'\n",
    "\n",
    "# Connexion √† la base\n",
    "engine = create_engine(PATH_BDD)\n",
    "\n",
    "# üì• Lire le fichier Parquet\n",
    "df = pd.read_parquet(FILE_PATH_PARQUET, engine='pyarrow')\n",
    "\n",
    "# Correspondance des colonnes (Parquet -> Table SQL)\n",
    "column_mapping = {\n",
    "    'finess_et': 'numero_finess',\n",
    "    'year': 'annee',\n",
    "    'month': 'mois',\n",
    "    'profession1': 'profession',\n",
    "    'turnover': 'turnover',\n",
    "    'entrees_taux':'entree_taux',\n",
    "    'sorties_taux':'entree_sortie',\n",
    "    'entrees':'entrees',\n",
    "    'sorties':'sorties',\n",
    "    'turnover_ref_region':'turnover_ref_region',\n",
    "    'turnover_ref_nation':'turnover_ref_nation',\n",
    "    'turnover_ref_categorie':'turnover_ref_categorie',\n",
    "}\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Supprimer les anciennes donn√©es AVANT insertion\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DELETE FROM vigie_rh_profession_filiere;\"))  # Supprime toutes les donn√©es\n",
    "    conn.commit()\n",
    "\n",
    "# Ins√©rer les nouvelles donn√©es en respectant la structure de la table\n",
    "df.to_sql(\n",
    "    'vigie_rh_profession_filiere', engine, \n",
    "    if_exists='append',  # Ajoute les nouvelles donn√©es sans modifier la structure\n",
    "    index=False,  # Ne pas ins√©rer l'index Pandas\n",
    "    chunksize=1000,  # Insertion par lots pour optimiser la performance\n",
    "    method='multi'  # Regrouper les INSERT pour am√©liorer la vitesse\n",
    ")\n",
    "\n",
    "print(\" Donn√©es ins√©r√©es avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple lecture table pour savoir si cel√† √©tait bien aliment√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine,text\n",
    "\n",
    "\n",
    "URL_BDD = 'postgresql://helios:h3li0s@localhost:5532/helios-preprod'\n",
    "\n",
    "# Cr√©er l'engine de connexion\n",
    "engine = create_engine(URL_BDD)\n",
    "\n",
    "# Requ√™te SQL pour v√©rifier les premi√®res lignes ins√©r√©es\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT * FROM vigie_rh_contrat LIMIT 5\"))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
